{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWsBJ4Xm8t2C"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#For Data folder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/payalmohapatra/MAESTRO\n",
        "#MAESTRO Model"
      ],
      "metadata": {
        "id": "pU6bHi7CqXp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import mne\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import math\n",
        "\n",
        "# ==============================================================================\n",
        "# ‚öôÔ∏è CONFIGURATION (UPDATED TO 500Hz)\n",
        "# ==============================================================================\n",
        "# Path to the BIDS-style root folder containing 'sub-01', 'sub-02', etc.\n",
        "DATA_ROOT = '/content/drive/MyDrive/sub-01'\n",
        "\n",
        "# Where to save the processed .pt tensors and models\n",
        "OUTPUT_DIR = '/content/MAESTRO_Project/processed_data'\n",
        "\n",
        "# Signal Processing Constants\n",
        "TARGET_SFREQ = 500  # <--- UPDATED to 500Hz\n",
        "CLIP_LEN_SEC = 1.5\n",
        "FIXED_LEN = int(TARGET_SFREQ * CLIP_LEN_SEC) # Now 750 samples (1.5 * 500)\n",
        "CHANNELS = ['Fz', 'FCz', 'Pz', 'Oz', 'C3', 'C4', 'P3', 'P4', 'ECG1']\n",
        "\n",
        "# Task-Specific File Mappings (Filename -> Class Label)\n",
        "NBACK_MAP = {'zeroBACK.set': 0, 'twoBACK.set': 1}\n",
        "MATB_MAP  = {'MATBeasy.set': 0, 'MATBdiff.set': 1}\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. PREPROCESSING ENGINE\n",
        "# ==============================================================================\n",
        "class MaestroPreprocessor:\n",
        "    def __init__(self, root_dir, output_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.output_dir = output_dir\n",
        "\n",
        "    def run(self):\n",
        "        print(f\"üöÄ STARTING MAESTRO PREPROCESSING PIPELINE (500Hz)\")\n",
        "        print(f\"üìÇ Scanning Path: {self.root_dir}\")\n",
        "\n",
        "        # Reset output directory to avoid shape mismatches\n",
        "        if os.path.exists(self.output_dir):\n",
        "            print(\"   ‚ö†Ô∏è Cleaning old output directory...\")\n",
        "            shutil.rmtree(self.output_dir)\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "        # üõ†Ô∏è SMART FIX: Check if root_dir IS the subject folder\n",
        "        folder_name = os.path.basename(self.root_dir.rstrip('/'))\n",
        "\n",
        "        if folder_name.startswith('sub-'):\n",
        "            print(f\"   ‚úÖ Detected target as Subject Folder: {folder_name}\")\n",
        "            self._process_subject(self.root_dir, folder_name)\n",
        "        else:\n",
        "            subjects = glob.glob(os.path.join(self.root_dir, 'sub-*'))\n",
        "            print(f\"   Found {len(subjects)} Subjects inside root.\")\n",
        "            for sub_path in subjects:\n",
        "                sub_id = os.path.basename(sub_path)\n",
        "                self._process_subject(sub_path, sub_id)\n",
        "\n",
        "    def _process_subject(self, sub_path, sub_id):\n",
        "        sessions = glob.glob(os.path.join(sub_path, 'ses-*'))\n",
        "        if not sessions:\n",
        "            print(f\"   ‚ö†Ô∏è No sessions (ses-*) found in {sub_id}\")\n",
        "            return\n",
        "\n",
        "        for ses_path in sessions:\n",
        "            ses_id = os.path.basename(ses_path)\n",
        "            eeg_path = os.path.join(ses_path, 'eeg')\n",
        "\n",
        "            if not os.path.exists(eeg_path):\n",
        "                print(f\"   ‚ö†Ô∏è No 'eeg' folder in {ses_id}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\n   Processing {sub_id} | {ses_id}...\")\n",
        "            self._process_pvt(eeg_path, sub_id, ses_id)\n",
        "            self._process_flanker(eeg_path, sub_id, ses_id)\n",
        "            self._process_continuous(eeg_path, sub_id, ses_id, 'NBACK', NBACK_MAP)\n",
        "            self._process_continuous(eeg_path, sub_id, ses_id, 'MATB', MATB_MAP)\n",
        "\n",
        "    def _save_tensor(self, data, label, task, sub, ses, idx):\n",
        "        task_dir = os.path.join(self.output_dir, task)\n",
        "        os.makedirs(task_dir, exist_ok=True)\n",
        "\n",
        "        # Transpose to [Time, Channels]\n",
        "        tensor = torch.tensor(data, dtype=torch.float32).transpose(0, 1)\n",
        "\n",
        "        # Force Fixed Length (Padding or Truncating)\n",
        "        if tensor.shape[0] != FIXED_LEN:\n",
        "            if tensor.shape[0] > FIXED_LEN:\n",
        "                tensor = tensor[:FIXED_LEN, :]\n",
        "            else:\n",
        "                tensor = torch.nn.functional.pad(tensor, (0, 0, 0, FIXED_LEN - tensor.shape[0]))\n",
        "\n",
        "        fname = f\"{sub}_{ses}_{label}_{idx}.pt\"\n",
        "        torch.save({'data': tensor, 'label': label}, os.path.join(task_dir, fname))\n",
        "\n",
        "    def _process_pvt(self, path, sub, ses):\n",
        "        fpath = os.path.join(path, 'PVT.set')\n",
        "        if not os.path.exists(fpath): return\n",
        "        try:\n",
        "            raw = mne.io.read_raw_eeglab(fpath, preload=True, verbose=False)\n",
        "            if not self._check_channels(raw): return\n",
        "\n",
        "            # Events logic\n",
        "            events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "            stim_id, resp_id = event_id.get('13'), event_id.get('14')\n",
        "\n",
        "            if stim_id and resp_id:\n",
        "                rts, valid_idx = [], []\n",
        "                for i in range(len(events)-1):\n",
        "                    if events[i,2] == stim_id and events[i+1,2] == resp_id:\n",
        "                        rts.append((events[i+1,0] - events[i,0]) / raw.info['sfreq'])\n",
        "                        valid_idx.append(i)\n",
        "\n",
        "                if rts:\n",
        "                    median_rt = np.median(rts)\n",
        "                    # Epoching\n",
        "                    epochs = mne.Epochs(raw, events[valid_idx], event_id=stim_id,\n",
        "                                      tmin=-1.0, tmax=0.5, baseline=None, verbose=False)\n",
        "                    data = epochs.get_data()\n",
        "\n",
        "                    for i, d in enumerate(data):\n",
        "                        label = 0 if rts[i] < median_rt else 1\n",
        "                        self._save_tensor(d, label, 'PVT', sub, ses, i)\n",
        "                    print(f\"      ‚úÖ PVT: Extracted {len(data)} trials\")\n",
        "        except Exception as e: print(f\"      ‚ùå PVT Error: {e}\")\n",
        "\n",
        "    def _process_flanker(self, path, sub, ses):\n",
        "        fpath = os.path.join(path, 'Flanker.set')\n",
        "        if not os.path.exists(fpath): return\n",
        "        try:\n",
        "            raw = mne.io.read_raw_eeglab(fpath, preload=True, verbose=False)\n",
        "            if not self._check_channels(raw): return\n",
        "\n",
        "            events, event_id = mne.events_from_annotations(raw, verbose=False)\n",
        "            mapping = {'2511': 0, '2521': 1}\n",
        "\n",
        "            total = 0\n",
        "            for marker, label in mapping.items():\n",
        "                if marker in event_id:\n",
        "                    epochs = mne.Epochs(raw, events, event_id=event_id[marker],\n",
        "                                      tmin=-1.0, tmax=0.5, baseline=None, verbose=False)\n",
        "                    data = epochs.get_data()\n",
        "                    for i, d in enumerate(data):\n",
        "                        self._save_tensor(d, label, 'FLANKER', sub, ses, f\"{marker}_{i}\")\n",
        "                        total += 1\n",
        "            if total > 0: print(f\"      ‚úÖ FLANKER: Extracted {total} trials\")\n",
        "        except Exception as e: print(f\"      ‚ùå FLANKER Error: {e}\")\n",
        "\n",
        "    def _process_continuous(self, path, sub, ses, task_name, file_map):\n",
        "        count = 0\n",
        "        for fname, label in file_map.items():\n",
        "            fpath = os.path.join(path, fname)\n",
        "            if not os.path.exists(fpath): continue\n",
        "            try:\n",
        "                raw = mne.io.read_raw_eeglab(fpath, preload=True, verbose=False)\n",
        "                if not self._check_channels(raw): continue\n",
        "\n",
        "                data = raw.get_data()\n",
        "                # Slicing continuous data\n",
        "                n_crops = data.shape[1] // FIXED_LEN\n",
        "                for i in range(n_crops):\n",
        "                    crop = data[:, i*FIXED_LEN : (i+1)*FIXED_LEN]\n",
        "                    self._save_tensor(crop, label, task_name, sub, ses, i)\n",
        "                    count += 1\n",
        "            except Exception: pass\n",
        "        if count > 0: print(f\"      ‚úÖ {task_name}: Extracted {count} trials\")\n",
        "\n",
        "    def _check_channels(self, raw):\n",
        "        # 1. Check if required channels exist\n",
        "        if not all(ch in raw.ch_names for ch in CHANNELS):\n",
        "            # Optional: Add logic here to try renaming channels if mismatch occurs\n",
        "            return False\n",
        "\n",
        "        # 2. Pick only the 9 required channels\n",
        "        raw.pick_channels(CHANNELS)\n",
        "\n",
        "        # 3. Resample if necessary (CRITICAL for 500Hz)\n",
        "        if raw.info['sfreq'] != TARGET_SFREQ:\n",
        "            raw.resample(TARGET_SFREQ, npad=\"auto\")\n",
        "\n",
        "        return True\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. TRAINING ENGINE (MAESTRO)\n",
        "# ==============================================================================\n",
        "class MAESTRO(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Input: [Batch, 750, 9] -> Projects to [Batch, 750, 64]\n",
        "        self.input_fc = nn.Linear(9, 64)\n",
        "\n",
        "        # Positional Encoding adjusted for 750 time steps\n",
        "        self.pos_encoder = nn.Parameter(torch.randn(1, FIXED_LEN, 64))\n",
        "\n",
        "        # Transformer Encoder\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=64, nhead=4, dim_feedforward=128,\n",
        "                                     batch_first=True, dropout=0.3),\n",
        "            num_layers=2\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.decoder = nn.Linear(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [Batch, 750, 9]\n",
        "        x = self.input_fc(x)\n",
        "\n",
        "        # Add position encoding (slicing safety for edge cases)\n",
        "        x = x + self.pos_encoder[:, :x.size(1), :]\n",
        "\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Global Average Pooling\n",
        "        return self.decoder(x.mean(dim=1))\n",
        "\n",
        "class MaestroDataset(Dataset):\n",
        "    def __init__(self, folder):\n",
        "        self.files = glob.glob(os.path.join(folder, \"*.pt\"))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # SECURITY UPDATE: weights_only=False\n",
        "        d = torch.load(self.files[idx], weights_only=False)\n",
        "        x = d['data'] # Shape: [750, 9]\n",
        "\n",
        "        # LESSON LEARNED: Z-Score Normalization\n",
        "        mean, std = x.mean(dim=0, keepdim=True), x.std(dim=0, keepdim=True) + 1e-8\n",
        "        x = (x - mean) / std\n",
        "\n",
        "        return x, d['label']\n",
        "\n",
        "def train_and_evaluate():\n",
        "    tasks = ['FLANKER', 'PVT', 'NBACK', 'MATB']\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"\\nüöÄ STARTING TRAINING ENGINE on {device}\")\n",
        "    print(f\"‚ÑπÔ∏è  Model Configuration: Input Length={FIXED_LEN}, Channels={len(CHANNELS)}\")\n",
        "\n",
        "    for task in tasks:\n",
        "        data_dir = os.path.join(OUTPUT_DIR, task)\n",
        "        if not os.path.exists(data_dir) or len(glob.glob(os.path.join(data_dir, \"*.pt\"))) == 0:\n",
        "            print(f\"‚ö†Ô∏è Skipping {task} (No data found)\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n\" + \"=\"*40)\n",
        "        print(f\"üß† TRAINING TASK: {task}\")\n",
        "        print(\"=\"*40)\n",
        "\n",
        "        dataset = MaestroDataset(data_dir)\n",
        "        if len(dataset) < 10:\n",
        "            print(\"‚ö†Ô∏è Not enough data to train.\")\n",
        "            continue\n",
        "\n",
        "        train_len = int(0.8 * len(dataset))\n",
        "        test_len = len(dataset) - train_len\n",
        "        train_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len])\n",
        "\n",
        "        # --- ‚öñÔ∏è AUTO-CALCULATE CLASS WEIGHTS ---\n",
        "        y_train = [d[1] for d in train_set] # Note: This is slow for huge datasets\n",
        "        count_0 = y_train.count(0)\n",
        "        count_1 = y_train.count(1)\n",
        "\n",
        "        if count_0 > 0 and count_1 > 0:\n",
        "            w0 = (count_0 + count_1) / (2.0 * count_0)\n",
        "            w1 = (count_0 + count_1) / (2.0 * count_1)\n",
        "            class_weights = torch.tensor([w0, w1], dtype=torch.float32).to(device)\n",
        "            print(f\"   ‚öñÔ∏è Class Balance: Low={count_0}, High={count_1}\")\n",
        "            print(f\"   ‚öñÔ∏è Applying Weights: Low={w0:.2f}, High={w1:.2f}\")\n",
        "        else:\n",
        "            class_weights = None\n",
        "            print(\"   ‚ö†Ô∏è Warning: One class is missing in training data!\")\n",
        "\n",
        "        train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "        test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "        model = MAESTRO().to(device)\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "        # --- TRAIN FOR 30 EPOCHS ---\n",
        "        for epoch in range(30):\n",
        "            model.train()\n",
        "            total_loss = 0\n",
        "            for x, y in train_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(model(x), y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                print(f\"   Epoch {epoch+1}/30 | Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        preds, targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for x, y in test_loader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                preds.extend(torch.argmax(out, 1).cpu().numpy())\n",
        "                targets.extend(y.cpu().numpy())\n",
        "\n",
        "        print(\"\\n\" + classification_report(targets, preds, target_names=['Low Load', 'High Load'], zero_division=0))\n",
        "\n",
        "        save_path = os.path.join(OUTPUT_DIR, f\"maestro_{task.lower()}_model.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"‚úÖ Model saved to: {save_path}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. EXECUTION BLOCK\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Run Preprocessing (Scan folders, slice data, save tensors)\n",
        "    processor = MaestroPreprocessor(DATA_ROOT, OUTPUT_DIR)\n",
        "    processor.run()\n",
        "\n",
        "    # 2. Run Training (Load tensors, train 4 expert models)\n",
        "    train_and_evaluate()"
      ],
      "metadata": {
        "id": "gncFKL_Y9O4v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}